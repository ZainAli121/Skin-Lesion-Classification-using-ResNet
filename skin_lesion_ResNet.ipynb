{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pre-trained ResNet","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nimport os\nimport glob\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom PIL import Image\nfrom sklearn.model_selection import GroupShuffleSplit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T11:04:48.435147Z","iopub.execute_input":"2025-12-21T11:04:48.435472Z","iopub.status.idle":"2025-12-21T11:04:48.440039Z","shell.execute_reply.started":"2025-12-21T11:04:48.435448Z","shell.execute_reply":"2025-12-21T11:04:48.439418Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"DEVICE:\", DEVICE)\n\nNUM_CLASSES = 7  # HAM10000 has 7 classes\n\n# Load a pretrained ResNet\nmodel = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n\n# Replace the last layer for our dataset classes\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features, NUM_CLASSES)\n\nif torch.cuda.device_count() > 1:\n    print(f\"ResNet Activated on {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)\n\nmodel = model.to(DEVICE)\nprint(\"ResNet Model Initialized!\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:43:55.224691Z","iopub.execute_input":"2025-12-21T10:43:55.225325Z","iopub.status.idle":"2025-12-21T10:43:55.460236Z","shell.execute_reply.started":"2025-12-21T10:43:55.225297Z","shell.execute_reply":"2025-12-21T10:43:55.459395Z"}},"outputs":[{"name":"stdout","text":"DEVICE: cuda\nResNet Activated on 2 GPUs!\nResNet Model Initialized!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Dataset import","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/skin-cancer-mnist-ham10000\"\n\nmetadata_path = os.path.join(DATA_DIR, \"HAM10000_metadata.csv\")\nimg_dir_1 = os.path.join(DATA_DIR, \"ham10000_images_part_1\")\nimg_dir_2 = os.path.join(DATA_DIR, \"ham10000_images_part_2\")\n\nif not os.path.exists(img_dir_1):\n    img_dir_1 = os.path.join(DATA_DIR, \"HAM10000_images_part_1\")\nif not os.path.exists(img_dir_2):\n    img_dir_2 = os.path.join(DATA_DIR, \"HAM10000_images_part_2\")\n\nassert os.path.exists(metadata_path), f\"Metadata not found at: {metadata_path}\"\nassert os.path.exists(img_dir_1), f\"Image folder not found: {img_dir_1}\"\nassert os.path.exists(img_dir_2), f\"Image folder not found: {img_dir_2}\"\n\nprint(\"Found metadata:\", metadata_path)\nprint(\"Found images:\", img_dir_1)\nprint(\"Found images:\", img_dir_2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:45:17.775961Z","iopub.execute_input":"2025-12-21T10:45:17.776641Z","iopub.status.idle":"2025-12-21T10:45:17.784641Z","shell.execute_reply.started":"2025-12-21T10:45:17.776618Z","shell.execute_reply":"2025-12-21T10:45:17.783974Z"}},"outputs":[{"name":"stdout","text":"Found metadata: /kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\nFound images: /kaggle/input/skin-cancer-mnist-ham10000/ham10000_images_part_1\nFound images: /kaggle/input/skin-cancer-mnist-ham10000/ham10000_images_part_2\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Read metadata","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(metadata_path)\n\n# Expected columns: image_id, lesion_id, dx (label)\nrequired_cols = {\"image_id\", \"lesion_id\", \"dx\"}\nmissing = required_cols - set(df.columns)\nassert not missing, f\"Missing columns in metadata: {missing}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:46:18.076505Z","iopub.execute_input":"2025-12-21T10:46:18.076770Z","iopub.status.idle":"2025-12-21T10:46:18.094802Z","shell.execute_reply.started":"2025-12-21T10:46:18.076751Z","shell.execute_reply":"2025-12-21T10:46:18.093935Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Build image_id -> filepath map","metadata":{}},{"cell_type":"code","source":"all_images = glob.glob(os.path.join(img_dir_1, \"*.jpg\")) + glob.glob(os.path.join(img_dir_2, \"*.jpg\"))\nid2path = {os.path.splitext(os.path.basename(p))[0]: p for p in all_images}\n\n# Attach image paths\ndf[\"path\"] = df[\"image_id\"].map(id2path)\ndf = df.dropna(subset=[\"path\"]).reset_index(drop=True)\n\nprint(\"Total images found:\", len(all_images))\nprint(\"Metadata rows with valid paths:\", len(df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:47:02.022555Z","iopub.execute_input":"2025-12-21T10:47:02.023167Z","iopub.status.idle":"2025-12-21T10:47:02.074120Z","shell.execute_reply.started":"2025-12-21T10:47:02.023146Z","shell.execute_reply":"2025-12-21T10:47:02.073474Z"}},"outputs":[{"name":"stdout","text":"Total images found: 10015\nMetadata rows with valid paths: 10015\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"##  Label encoding","metadata":{}},{"cell_type":"code","source":"classes = sorted(df[\"dx\"].unique().tolist())\nclass_to_idx = {c: i for i, c in enumerate(classes)}\nidx_to_class = {i: c for c, i in class_to_idx.items()}\n\ndf[\"label\"] = df[\"dx\"].map(class_to_idx).astype(int)\n\nprint(\"Classes:\", classes)\nprint(\"Class counts:\\n\", df[\"dx\"].value_counts())\n\n#Classes: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:49:28.633585Z","iopub.execute_input":"2025-12-21T10:49:28.634158Z","iopub.status.idle":"2025-12-21T10:49:28.643350Z","shell.execute_reply.started":"2025-12-21T10:49:28.634131Z","shell.execute_reply":"2025-12-21T10:49:28.642629Z"}},"outputs":[{"name":"stdout","text":"Classes: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\nClass counts:\n dx\nnv       6705\nmel      1113\nbkl      1099\nbcc       514\nakiec     327\nvasc      142\ndf        115\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Split data","metadata":{}},{"cell_type":"code","source":"# divide into 70%, 30%\ngss1 = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\ntrain_idx, temp_idx = next(gss1.split(df, groups=df[\"lesion_id\"]))\n\ntrain_df = df.iloc[train_idx].reset_index(drop=True)  # 70%\ntemp_df = df.iloc[temp_idx].reset_index(drop=True)   # 30%\n\n# split that 30% of test to further 15, 15 for test and validation\ngss2 = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=42)\nval_idx, test_idx = next(gss2.split(temp_df, groups=temp_df[\"lesion_id\"]))\n\nval_df = temp_df.iloc[val_idx].reset_index(drop=True)\ntest_df = temp_df.iloc[test_idx].reset_index(drop=True)\n\nprint(\"\\nSplit sizes:\")\nprint(\"Train:\", len(train_df))\nprint(\"Val:  \", len(val_df))\nprint(\"Test: \", len(test_df))\n\n# Quick safety check: no lesion_id overlap\ntrain_lesions = set(train_df[\"lesion_id\"])\nval_lesions = set(val_df[\"lesion_id\"])\ntest_lesions = set(test_df[\"lesion_id\"])\n\nassert train_lesions.isdisjoint(val_lesions)\nassert train_lesions.isdisjoint(test_lesions)\nassert val_lesions.isdisjoint(test_lesions)\n\nprint(\"Lesion-level split verified (no leakage).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:53:06.464949Z","iopub.execute_input":"2025-12-21T10:53:06.465294Z","iopub.status.idle":"2025-12-21T10:53:06.489514Z","shell.execute_reply.started":"2025-12-21T10:53:06.465275Z","shell.execute_reply":"2025-12-21T10:53:06.488849Z"}},"outputs":[{"name":"stdout","text":"\nSplit sizes:\nTrain: 7002\nVal:   1519\nTest:  1494\nLesion-level split verified (no leakage).\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Transforms (ResNet expects 224x224 + ImageNet normalization)","metadata":{}},{"cell_type":"code","source":"train_tfms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.RandomRotation(degrees=20),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\neval_tfms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:54:28.158535Z","iopub.execute_input":"2025-12-21T10:54:28.159521Z","iopub.status.idle":"2025-12-21T10:54:28.164784Z","shell.execute_reply.started":"2025-12-21T10:54:28.159489Z","shell.execute_reply":"2025-12-21T10:54:28.163981Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# Dataset class","metadata":{}},{"cell_type":"code","source":"class HAM10000Dataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row[\"path\"]).convert(\"RGB\")\n        y = int(row[\"label\"])\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, y\n\ntrain_ds = HAM10000Dataset(train_df, transform=train_tfms)\nval_ds   = HAM10000Dataset(val_df, transform=eval_tfms)\ntest_ds  = HAM10000Dataset(test_df, transform=eval_tfms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:57:20.175811Z","iopub.execute_input":"2025-12-21T10:57:20.176347Z","iopub.status.idle":"2025-12-21T10:57:20.181824Z","shell.execute_reply.started":"2025-12-21T10:57:20.176325Z","shell.execute_reply":"2025-12-21T10:57:20.181129Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"# DataLoaders","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64 \nNUM_WORKERS = 2\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n                          num_workers=NUM_WORKERS, pin_memory=True)\nval_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n                          num_workers=NUM_WORKERS, pin_memory=True)\ntest_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n                          num_workers=NUM_WORKERS, pin_memory=True)\n\nprint(\"\\n DataLoaders ready!\")\nprint(\"Batches per epoch:\", len(train_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T10:59:49.594946Z","iopub.execute_input":"2025-12-21T10:59:49.595301Z","iopub.status.idle":"2025-12-21T10:59:49.601073Z","shell.execute_reply.started":"2025-12-21T10:59:49.595276Z","shell.execute_reply":"2025-12-21T10:59:49.600243Z"}},"outputs":[{"name":"stdout","text":"\n DataLoaders ready!\nBatches per epoch: 110\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# Class weights","metadata":{}},{"cell_type":"code","source":"class_counts = train_df[\"label\"].value_counts().sort_index().values  # count per class index\nclass_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32)\nclass_weights = class_weights / class_weights.sum() * len(class_counts)  # normalize around num_classes\nclass_weights = class_weights.to(DEVICE)\n\nprint(\"Class counts:\", class_counts)\nprint(\"Class weights:\", class_weights.detach().cpu().numpy())\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T11:02:19.032956Z","iopub.execute_input":"2025-12-21T11:02:19.033771Z","iopub.status.idle":"2025-12-21T11:02:19.042013Z","shell.execute_reply.started":"2025-12-21T11:02:19.033743Z","shell.execute_reply":"2025-12-21T11:02:19.041102Z"}},"outputs":[{"name":"stdout","text":"Class counts: [ 207  381  741   89  770 4718   96]\nClass weights: [1.057808   0.5747146  0.29550102 2.460295   0.28437176 0.04641082\n 2.2808986 ]\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"# Optimizer + scheduler","metadata":{}},{"cell_type":"code","source":"LR = 3e-4\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n\n# Scheduler: reduce LR when val loss plateaus\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T11:03:29.594650Z","iopub.execute_input":"2025-12-21T11:03:29.595265Z","iopub.status.idle":"2025-12-21T11:03:29.602194Z","shell.execute_reply.started":"2025-12-21T11:03:29.595239Z","shell.execute_reply":"2025-12-21T11:03:29.601481Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# Train / Eval functions","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in tqdm(loader, desc=\"Train\", leave=False):\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n        logits = model(images)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        preds = torch.argmax(logits, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n\n@torch.no_grad()\ndef evaluate(model, loader, criterion, device, desc=\"Val\"):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in tqdm(loader, desc=desc, leave=False):\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n\n        logits = model(images)\n        loss = criterion(logits, labels)\n\n        running_loss += loss.item() * images.size(0)\n        preds = torch.argmax(logits, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T11:04:57.615733Z","iopub.execute_input":"2025-12-21T11:04:57.616014Z","iopub.status.idle":"2025-12-21T11:04:57.623695Z","shell.execute_reply.started":"2025-12-21T11:04:57.615993Z","shell.execute_reply":"2025-12-21T11:04:57.622986Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"# training loop","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10  # start with 10; can increase later\n\nbest_val_acc = 0.0\nbest_path = \"best_resnet_ham10000.pt\"\n\nhistory = {\n    \"train_loss\": [], \"train_acc\": [],\n    \"val_loss\": [], \"val_acc\": []\n}\n\nfor epoch in range(1, EPOCHS + 1):\n    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n\n    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n    val_loss, val_acc = evaluate(model, val_loader, criterion, DEVICE, desc=\"Val\")\n\n    history[\"train_loss\"].append(train_loss)\n    history[\"train_acc\"].append(train_acc)\n    history[\"val_loss\"].append(val_loss)\n    history[\"val_acc\"].append(val_acc)\n\n    print(f\"Train: loss={train_loss:.4f}, acc={train_acc:.4f}\")\n    print(f\"Val:   loss={val_loss:.4f}, acc={val_acc:.4f}\")\n\n    scheduler.step(val_loss)\n\n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save({\n            \"model_state\": model.state_dict() if not isinstance(model, nn.DataParallel) else model.module.state_dict(),\n            \"class_to_idx\": class_to_idx,\n            \"idx_to_class\": idx_to_class,\n            \"classes\": classes\n        }, best_path)\n        print(f\"Saved best model to {best_path} (val_acc={best_val_acc:.4f})\")\n\nprint(\"\\nTraining done. Best Val Acc:\", best_val_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T11:05:57.684016Z","iopub.execute_input":"2025-12-21T11:05:57.684335Z","iopub.status.idle":"2025-12-21T11:15:45.900161Z","shell.execute_reply.started":"2025-12-21T11:05:57.684312Z","shell.execute_reply":"2025-12-21T11:15:45.899244Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=1.2313, acc=0.5453\nVal:   loss=1.1801, acc=0.5951\nSaved best model to best_resnet_ham10000.pt (val_acc=0.5951)\n\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.9050, acc=0.6561\nVal:   loss=1.2097, acc=0.5932\n\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.7690, acc=0.6925\nVal:   loss=1.0333, acc=0.6406\nSaved best model to best_resnet_ham10000.pt (val_acc=0.6406)\n\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.6615, acc=0.7142\nVal:   loss=0.6986, acc=0.7505\nSaved best model to best_resnet_ham10000.pt (val_acc=0.7505)\n\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.6128, acc=0.7346\nVal:   loss=1.2373, acc=0.6004\n\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.6149, acc=0.7191\nVal:   loss=1.2204, acc=0.6228\n\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.5538, acc=0.7334\nVal:   loss=0.8733, acc=0.6880\n\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.3902, acc=0.7909\nVal:   loss=0.9767, acc=0.7024\n\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.3413, acc=0.8033\nVal:   loss=0.8491, acc=0.7215\n\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"                                                        ","output_type":"stream"},{"name":"stdout","text":"Train: loss=0.3060, acc=0.8268\nVal:   loss=0.6998, acc=0.7841\nSaved best model to best_resnet_ham10000.pt (val_acc=0.7841)\n\nTraining done. Best Val Acc: 0.7840684660961159\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"best_path = \"best_resnet_ham10000.pt\"\nckpt = torch.load(best_path, map_location=DEVICE)\n\n# restore weights (handles DataParallel vs not)\nif isinstance(model, nn.DataParallel):\n    model.module.load_state_dict(ckpt[\"model_state\"])\nelse:\n    model.load_state_dict(ckpt[\"model_state\"])\n\nmodel = model.to(DEVICE)\nmodel.eval()\n\n# restore label maps (useful for reporting)\nidx_to_class = ckpt[\"idx_to_class\"]\nclasses = ckpt[\"classes\"]\n\nprint(\"Loaded best model:\", best_path)\nprint(\"Classes:\", classes)\n\nall_preds = []\nall_labels = []\n\n@torch.no_grad()\ndef predict_all(model, loader, device):\n    preds_list, labels_list = [], []\n    for images, labels in loader:\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n\n        logits = model(images)\n        preds = torch.argmax(logits, dim=1)\n\n        preds_list.append(preds.detach().cpu())\n        labels_list.append(labels.detach().cpu())\n\n    preds_list = torch.cat(preds_list).numpy()\n    labels_list = torch.cat(labels_list).numpy()\n    return preds_list, labels_list\n\nall_preds, all_labels = predict_all(model, test_loader, DEVICE)\n\n\ntest_acc = (all_preds == all_labels).mean()\nprint(f\"\\n Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T11:50:42.003679Z","iopub.execute_input":"2025-12-21T11:50:42.003967Z","iopub.status.idle":"2025-12-21T11:50:50.244820Z","shell.execute_reply.started":"2025-12-21T11:50:42.003943Z","shell.execute_reply":"2025-12-21T11:50:50.244003Z"}},"outputs":[{"name":"stdout","text":"Loaded best model: best_resnet_ham10000.pt\nClasses: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n\n Test Accuracy: 0.7798 (77.98%)\n","output_type":"stream"}],"execution_count":51}]}